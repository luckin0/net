{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "1mM2XrF4noDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)"
      ],
      "metadata": {
        "id": "h5NP0BrHnpd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChannelAttentionModule(nn.Module):\n",
        "    \"\"\" Channel attention module \"\"\"\n",
        "    def __init__(self, in_channels, reduction_ratio=16):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels // reduction_ratio, 1, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels // reduction_ratio, in_channels, 1, bias=False)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc(self.avg_pool(x))\n",
        "        max_out = self.fc(self.max_pool(x))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class SpatialAttentionModule(nn.Module):\n",
        "    \"\"\" Spatial attention module \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv3x3 = nn.Conv2d(2, 1, kernel_size=3, stride=1, padding=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x = torch.cat([avg_out, max_out], dim=1)\n",
        "        x = self.conv3x3(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "class DualAttentionModule(nn.Module):\n",
        "    \"\"\" Dual attention module \"\"\"\n",
        "    def __init__(self, in_channels, reduction_ratio=16):\n",
        "        super().__init__()\n",
        "        self.channel_attention = ChannelAttentionModule(in_channels, reduction_ratio)\n",
        "        self.spatial_attention = SpatialAttentionModule()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply channel attention\n",
        "        x = x * self.channel_attention(x)\n",
        "        # Apply spatial attention\n",
        "        x = x * self.spatial_attention(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "5IBBpYBXnsD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetWithDualAttention(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNetWithDualAttention, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = DoubleConv(64, 128)\n",
        "        self.down2 = DoubleConv(128, 256)\n",
        "        self.down3 = DoubleConv(256, 512)\n",
        "        self.dam1 = DualAttentionModule(512)  # Dual attention module\n",
        "        self.up1 = DoubleConv(256 + 512, 256)\n",
        "        self.up2 = DoubleConv(128 + 256, 128)\n",
        "        self.up3 = DoubleConv(64 + 128, 64)\n",
        "        self.dam2 = DualAttentionModule(64)  # Dual attention module\n",
        "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = F.max_pool2d(x1, 2)\n",
        "        x2 = self.down1(x2)\n",
        "        x3 = F.max_pool2d(x2, 2)\n",
        "        x3 = self.down2(x3)\n",
        "        x4 = F.max_pool2d(x3, 2)\n",
        "        x4 = self.down3(x4)\n",
        "\n",
        "        x4 = self.dam1(x4)  # Apply dual attention module\n",
        "\n",
        "        x = F.interpolate(x4, scale_factor=2, mode='bilinear', align_corners=True) if self.bilinear else F.conv_transpose2d(x4, self.up1.weight, stride=2)\n",
        "        x = torch.cat([x, x3], dim=1)\n",
        "        x = self.up1(x)\n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True) if self.bilinear else F.conv_transpose2d(x, self.up2.weight, stride=2)\n",
        "        x = torch.cat([x, x2], dim=1)\n",
        "        x = self.up2(x)\n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True) if self.bilinear else F.conv_transpose2d(x, self.up3.weight, stride=2)\n",
        "        x = torch.cat([x, x1], dim=1)\n",
        "        x = self.up3(x)\n",
        "\n",
        "        x = self.dam2(x)  # Apply dual attention module\n",
        "\n",
        "        logits = self.outc(x)\n",
        "        return logits\n",
        "\n",
        "# Create the model\n",
        "model = UNetWithDualAttention(n_channels=3, n_classes=1)"
      ],
      "metadata": {
        "id": "H0P3p3bWnzcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irh-BtVhn0si",
        "outputId": "7f377bc4-eac6-4e31-c35f-0d51a5779998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNetWithDualAttention(\n",
            "  (inc): DoubleConv(\n",
            "    (double_conv): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (down1): DoubleConv(\n",
            "    (double_conv): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (down2): DoubleConv(\n",
            "    (double_conv): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (down3): DoubleConv(\n",
            "    (double_conv): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (dam1): DualAttentionModule(\n",
            "    (channel_attention): ChannelAttentionModule(\n",
            "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
            "      (fc): Sequential(\n",
            "        (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (sigmoid): Sigmoid()\n",
            "    )\n",
            "    (spatial_attention): SpatialAttentionModule(\n",
            "      (conv3x3): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (sigmoid): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (up1): DoubleConv(\n",
            "    (double_conv): Sequential(\n",
            "      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (up2): DoubleConv(\n",
            "    (double_conv): Sequential(\n",
            "      (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (up3): DoubleConv(\n",
            "    (double_conv): Sequential(\n",
            "      (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (dam2): DualAttentionModule(\n",
            "    (channel_attention): ChannelAttentionModule(\n",
            "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
            "      (fc): Sequential(\n",
            "        (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (sigmoid): Sigmoid()\n",
            "    )\n",
            "    (spatial_attention): SpatialAttentionModule(\n",
            "      (conv3x3): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (sigmoid): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (outc): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetWithDualAttention(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNetWithDualAttention, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = DoubleConv(64, 128)\n",
        "        self.down2 = DoubleConv(128, 256)\n",
        "        self.down3 = DoubleConv(256, 512)\n",
        "        self.dam1 = DualAttentionModule(512)  # Dual attention module\n",
        "        self.up1 = DoubleConv(256 + 512, 256)\n",
        "        self.up2 = DoubleConv(128 + 256, 128)\n",
        "        self.up3 = DoubleConv(64 + 128, 64)\n",
        "        self.dam2 = DualAttentionModule(64)  # Dual attention module\n",
        "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        sizes = []\n",
        "        x1 = self.inc(x)\n",
        "        sizes.append(x1.size())\n",
        "        x2 = F.max_pool2d(x1, 2)\n",
        "        x2 = self.down1(x2)\n",
        "        sizes.append(x2.size())\n",
        "        x3 = F.max_pool2d(x2, 2)\n",
        "        x3 = self.down2(x3)\n",
        "        sizes.append(x3.size())\n",
        "        x4 = F.max_pool2d(x3, 2)\n",
        "        x4 = self.down3(x4)\n",
        "        sizes.append(x4.size())\n",
        "\n",
        "        x4 = self.dam1(x4)  # Apply dual attention module\n",
        "        sizes.append(x4.size())\n",
        "\n",
        "        x = F.interpolate(x4, scale_factor=2, mode='bilinear', align_corners=True) if self.bilinear else F.conv_transpose2d(x4, self.up1.weight, stride=2)\n",
        "        x = torch.cat([x, x3], dim=1)\n",
        "        x = self.up1(x)\n",
        "        sizes.append(x.size())\n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True) if self.bilinear else F.conv_transpose2d(x, self.up2.weight, stride=2)\n",
        "        x = torch.cat([x, x2], dim=1)\n",
        "        x = self.up2(x)\n",
        "        sizes.append(x.size())\n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True) if self.bilinear else F.conv_transpose2d(x, self.up3.weight, stride=2)\n",
        "        x = torch.cat([x, x1], dim=1)\n",
        "        x = self.up3(x)\n",
        "        sizes.append(x.size())\n",
        "\n",
        "        x = self.dam2(x)  # Apply dual attention module\n",
        "        sizes.append(x.size())\n",
        "\n",
        "        logits = self.outc(x)\n",
        "        sizes.append(logits.size())\n",
        "        return logits, sizes\n",
        "\n",
        "# Create the model\n",
        "model = UNetWithDualAttention(n_channels=3, n_classes=1)\n",
        "\n",
        "# Create a dummy input tensor of size (1, 3, 256, 256) (batch_size, channels, height, width)\n",
        "dummy_input = torch.randn(1, 3, 256, 256)\n",
        "\n",
        "# Forward pass through the model to get the size of feature maps after each layer\n",
        "_, sizes = model(dummy_input)\n",
        "\n",
        "# Output the sizes\n",
        "for i, size in enumerate(sizes, start=1):\n",
        "    print(f\"Layer {i} output size: {size}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zca7uNr7olPD",
        "outputId": "5349a23a-fa0f-4123-a1be-2558b2537bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 output size: torch.Size([1, 64, 256, 256])\n",
            "Layer 2 output size: torch.Size([1, 128, 128, 128])\n",
            "Layer 3 output size: torch.Size([1, 256, 64, 64])\n",
            "Layer 4 output size: torch.Size([1, 512, 32, 32])\n",
            "Layer 5 output size: torch.Size([1, 512, 32, 32])\n",
            "Layer 6 output size: torch.Size([1, 256, 64, 64])\n",
            "Layer 7 output size: torch.Size([1, 128, 128, 128])\n",
            "Layer 8 output size: torch.Size([1, 64, 256, 256])\n",
            "Layer 9 output size: torch.Size([1, 64, 256, 256])\n",
            "Layer 10 output size: torch.Size([1, 1, 256, 256])\n"
          ]
        }
      ]
    }
  ]
}